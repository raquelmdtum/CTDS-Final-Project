{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index\n",
       "0     [Vegan, HyaluronicAcid, allure2019BestofBeauty...\n",
       "1     [Vegan, CommunityFavorite, AHA, GlycolicAcid, ...\n",
       "2     [CommunityFavorite, AHA, GlycolicAcid, OilFree...\n",
       "3     [Vegan, CommunityFavorite, DarkCircles, OilFre...\n",
       "4     [Vegan, CommunityFavorite, WithoutSilicones, A...\n",
       "5     [Vegan, WithoutSilicones, AlcoholFree, GlutenF...\n",
       "6     [Vegan, CommunityFavorite, OilFree, WithoutSil...\n",
       "7     [Vegan, LacticAcid, CommunityFavorite, Without...\n",
       "8     [Vegan, Dullness, UnevenTexture, VitaminC, Ant...\n",
       "9     [Vegan, CommunityFavorite, OilFree, AlcoholFre...\n",
       "10    [Vegan, Hydrating, Dryness, WithoutParabens, W...\n",
       "11    [Vegan, WithoutSilicones, AlcoholFree, GlutenF...\n",
       "12    [Vegan, Dullness, UnevenTexture, Retinol, Anti...\n",
       "13    [Vegan, CommunityFavorite, SalicylicAcid, With...\n",
       "14    [Vegan, Anti-Aging, WithoutParabens, WithoutSu...\n",
       "15    [Vegan, Dullness, UnevenTexture, Acne, Blemish...\n",
       "16    [Vegan, Dullness, UnevenTexture, VitaminC, Ant...\n",
       "17    [Vegan, Dry, WithoutParabens, GlutenFree, With...\n",
       "18    [Vegan, FragranceFree, Acne, Blemishes, Salicy...\n",
       "19    [Vegan, OilFree, WithoutSilicones, AlcoholFree...\n",
       "20    [Vegan, Anti-Aging, FragranceFree, WithoutPara...\n",
       "21    [Vegan, Dullness, UnevenTexture, Dryness, With...\n",
       "22    [Vegan, Dry, Dryness, WithoutParabens, Without...\n",
       "23    [Vegan, Anti-Aging, WithoutPhthalates, Fragran...\n",
       "24    [Vegan, Lossoffirmness, Dryness, WithoutParabe...\n",
       "25    [Vegan, LiquidFormula, DarkCircles, Anti-Aging...\n",
       "26    [Vegan, Lossoffirmness, Dryness, FragranceFree...\n",
       "27    [Vegan, LoosePowderFormula, Dullness, UnevenTe...\n",
       "28    [Vegan, Dullness, UnevenTexture, LacticAcid, A...\n",
       "29    [Vegan, Dullness, UnevenTexture, VitaminC, Fra...\n",
       "30    [Vegan, FragranceFree, WithoutParabens, Withou...\n",
       "31    [Vegan, Anti-Aging, WithoutParabens, WithoutSu...\n",
       "32    [Vegan, Redness, Lossoffirmness, WithoutParabe...\n",
       "33    [Vegan, Hydrating, Dryness, WithoutParabens, W...\n",
       "34    [Vegan, LoosePowderFormula, Oily, Combo, Norma...\n",
       "35    [Vegan, CommunityFavorite, WithoutSilicones, A...\n",
       "36    [Vegan, Dullness, UnevenTexture, WithoutParabe...\n",
       "37    [Vegan, FragranceFree, SalicylicAcid, Acne, Bl...\n",
       "38    [Vegan, Dullness, UnevenTexture, Anti-Aging, W...\n",
       "39    [Vegan, Dullness, UnevenTexture, FragranceFree...\n",
       "40    [Vegan, HyaluronicAcid, DarkCircles, Dryness, ...\n",
       "41    [Vegan, LiquidFormula, FragranceFree, OilFree,...\n",
       "Name: Vegan, Community Favorite, Oil Free, Without Silicones, Niacinamide, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "skincare_df = pd.read_csv(Path('data/Skincare.csv'))\n",
    "skincare_df.index.rename('index', inplace=True)\n",
    "#ingredients_df = skincare_df.iloc[:, 11].str.split(',')\n",
    "\n",
    "# Remove text within parentheses and strip extra spaces\n",
    "ingredients_df = skincare_df.iloc[:, 11].str.replace(r'\\(.*?\\)', '', regex=True).str.replace(' ', '', regex=False).str.replace(r'\\*', '', regex=True).str.split(',').apply(lambda x: [item.strip() for item in x])\n",
    "#ingredients_df = skincare_df.iloc[:, 11].str.replace(r'[^\\w\\s]', '', regex=True).str.replace(' ', '', regex=False).str.split(',')\n",
    "tags_df = skincare_df.iloc[:, 20].str.replace(r'\\(.*?\\)', '', regex=True).str.replace(' ', '', regex=False).str.replace(r'\\*', '', regex=True).str.split(',').apply(lambda x: [item.strip() for item in x])\n",
    "tags_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune(data, supp):\n",
    "    \"\"\"Filter itemsets by support count threshold.\"\"\"\n",
    "    return data[data.supp_count >= supp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_itemsets(ingredients_df, itemsets):\n",
    "    \"\"\"Count occurrences of each itemset in the transaction data.\"\"\"\n",
    "    count_item = {}\n",
    "    for item_set in tqdm(itemsets, desc=\"Counting itemsets\"):\n",
    "        set_A = set(item_set)\n",
    "        for row in ingredients_df:\n",
    "            set_B = set(row)\n",
    "            if set_B.intersection(set_A) == set_A: \n",
    "                if item_set in count_item:\n",
    "                    count_item[item_set] += 1\n",
    "                else:\n",
    "                    count_item[item_set] = 1\n",
    "    data = pd.DataFrame({\n",
    "        'item_sets': list(count_item.keys()),\n",
    "        'supp_count': list(count_item.values())\n",
    "    })\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_individual_items(ingr_items):\n",
    "    \"\"\"Count occurrences of individual items.\"\"\"\n",
    "    count_ind_item = {}\n",
    "    for row in tqdm(ingr_items, desc=\"Counting individual items\"):\n",
    "        for item in row:\n",
    "            if item in count_ind_item:\n",
    "                count_ind_item[item] += 1\n",
    "            else:\n",
    "                count_ind_item[item] = 1\n",
    "    data = pd.DataFrame({\n",
    "        'item_sets': list(count_ind_item.keys()),\n",
    "        'supp_count': list(count_ind_item.values())\n",
    "    }).sort_values('item_sets')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join(list_of_items):\n",
    "    \"\"\"Generate candidate itemsets by joining item pairs.\"\"\"\n",
    "    itemsets = []\n",
    "    list_length = len(list_of_items)\n",
    "    for i, entry in enumerate(tqdm(list_of_items, desc=\"Joining itemsets\", leave=False)):\n",
    "        for item in list_of_items[i+1:]:\n",
    "            if isinstance(item, str):\n",
    "                if entry != item:\n",
    "                    tuples = (entry, item)\n",
    "                    itemsets.append(tuples)\n",
    "            else:\n",
    "                if entry[:-1] == item[:-1]:\n",
    "                    tuples = entry + item[1:]\n",
    "                    itemsets.append(tuples)\n",
    "    return itemsets if itemsets else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apriori(ingr_data, supp=3, con=0.5):\n",
    "    \"\"\"Apriori algorithm for finding frequent itemsets.\"\"\"\n",
    "    freq = pd.DataFrame()\n",
    "    df = count_individual_items(ingr_data)\n",
    "    \n",
    "    while not df.empty:\n",
    "        df = prune(df, supp)\n",
    "        if not df.empty:\n",
    "            freq = pd.concat([freq, df])\n",
    "        itemsets = join(df.item_sets)\n",
    "        if itemsets is None:\n",
    "            break\n",
    "        df = count_itemsets(ingr_data, itemsets)\n",
    "    \n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Convert ingredients and tags into a transaction dataset format\n",
    "# Ensure `transaction_df` is a one-hot encoded DataFrame with ingredients and tags as columns\n",
    "\n",
    "# Get frequent itemsets\n",
    "frequent_itemsets = apriori(ingredients_df, min_support=0.03, use_colnames=True)\n",
    "\n",
    "# Generate association rules with ingredients as antecedents and tags as consequents\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.5)\n",
    "\n",
    "# Filter rules to focus on ingredient -> tag associations\n",
    "rules = rules[rules['consequents'].apply(lambda x: any(tag in x for tag in tags_list))]\n",
    "\n",
    "# Display the rules\n",
    "print(rules[['antecedents', 'consequents', 'support', 'confidence']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_item_sets = apriori(ingredients_df, supp=4)\n",
    "print(freq_item_sets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
