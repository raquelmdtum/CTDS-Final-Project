{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the data (run only once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\perwj\\anaconda3\\envs\\ML\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/nadyinky/sephora-products-and-skincare-reviews?dataset_version_number=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147M/147M [01:29<00:00, 1.71MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\perwj\\.cache\\kagglehub\\datasets\\nadyinky\\sephora-products-and-skincare-reviews\\versions\\2\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"nadyinky/sephora-products-and-skincare-reviews\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and clean the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Makeup', 'Skincare', 'Fragrance', 'Mini Size', 'Hair', 'Bath & Body', 'Men', 'Gifts', 'Tools & Brushes'}\n",
      "Skin care data size 2420\n",
      "Skin care data size after removing empty highlights 2003\n",
      "Skin care data size after removing empty ingredients 1927\n",
      "Skin care data size after removing empty secondary_category 1927\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV data into a DataFrame\n",
    "df = pd.read_csv(\"data/product_info.csv\")\n",
    "\n",
    "primary_category = set(df['primary_category'])\n",
    "print(primary_category)\n",
    "\n",
    "# Filter the DataFrame for rows where 'primary_category' is 'Skincare'\n",
    "skincare_df = df[df['primary_category'] == 'Skincare']\n",
    "\n",
    "# Display data size\n",
    "print(\"Skin care data size\", len(skincare_df))\n",
    "\n",
    "# remove rows where highlight are non existent\n",
    "skincare_df = skincare_df[skincare_df['highlights'].notna() & (skincare_df['highlights'] != '')]\n",
    "\n",
    "print(\"Skin care data size after removing empty highlights\",len(skincare_df))\n",
    "\n",
    "# remove rows where ingredients are non existent\n",
    "skincare_df = skincare_df[skincare_df['ingredients'].notna() & (skincare_df['ingredients'] != '')]\n",
    "\n",
    "print(\"Skin care data size after removing empty ingredients\",len(skincare_df))\n",
    "\n",
    "# remove where the secondary_category is empty\n",
    "skincare_df = skincare_df[skincare_df['secondary_category'].notna() & (skincare_df['secondary_category'] != '')]\n",
    "\n",
    "print(\"Skin care data size after removing empty secondary_category\",len(skincare_df))\n",
    "\n",
    "# # remove where the tertiary_category is empty\n",
    "# skincare_df = skincare_df[skincare_df['tertiary_category'].notna() & (skincare_df['tertiary_category'] != '')]\n",
    "# print(\"Skin care data size after removing empty tertiary_category\",len(skincare_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean highlights column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlights = skincare_df['highlights']\n",
    "\n",
    "highlights = [h.replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\").replace(\"Best for \", \"\").replace(\"Good for: \", \"\").replace(\" Skin\", \"\").replace(\"/\", \", \") for h in highlights]\n",
    "\n",
    "skincare_df['highlights'] = highlights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "skincare_df.to_csv('data/skincare.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\perwj\\AppData\\Local\\Temp\\ipykernel_17188\\2568968107.py:2: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"data/reviews_0-250.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602130\n",
      "545756\n",
      "Different users,  383697\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV data into a DataFrame\n",
    "df = pd.read_csv(\"data/reviews_0-250.csv\")\n",
    "\n",
    "product_ids = skincare_df['product_id']\n",
    "print(len(df))\n",
    "\n",
    "df_review1 = df[df['product_id'].isin(product_ids)]\n",
    "print(len(df_review1))\n",
    "print(\"Different users, \", len(set(df['author_id'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\perwj\\AppData\\Local\\Temp\\ipykernel_17188\\1564603506.py:7: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_4 = pd.read_csv(\"data/reviews_750-1250.csv\")\n",
      "C:\\Users\\perwj\\AppData\\Local\\Temp\\ipykernel_17188\\1564603506.py:10: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_5 = pd.read_csv(\"data/reviews_1250-end.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "966018\n",
      "513998\n"
     ]
    }
   ],
   "source": [
    "df_2 = pd.read_csv(\"data/reviews_250-500.csv\")\n",
    "df_review2 = df_2[df_2['product_id'].isin(product_ids)]\n",
    "\n",
    "df_3 = pd.read_csv(\"data/reviews_500-750.csv\")\n",
    "df_review3 = df_3[df_3['product_id'].isin(product_ids)]\n",
    "\n",
    "df_4 = pd.read_csv(\"data/reviews_750-1250.csv\")\n",
    "df_review4 = df_4[df_4['product_id'].isin(product_ids)]\n",
    "\n",
    "df_5 = pd.read_csv(\"data/reviews_1250-end.csv\")\n",
    "df_review5 = df_5[df_5['product_id'].isin(product_ids)]\n",
    "\n",
    "combined_df = pd.concat([df_review2, df_review1], axis=0, ignore_index=True)\n",
    "combined_df = pd.concat([combined_df, df_review3], axis=0, ignore_index=True)\n",
    "combined_df = pd.concat([combined_df, df_review4], axis=0, ignore_index=True)\n",
    "combined_df = pd.concat([combined_df, df_review5], axis=0, ignore_index=True)\n",
    "\n",
    "print(len(combined_df))\n",
    "print(len(set(combined_df['author_id'])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users with at least 7 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_in_product_name = combined_df['product_name'].str.contains('mini', case=False, na=False)\n",
    "limited_edition_in_product_name = combined_df['product_name'].str.contains('limited edition', case=False, na=False)\n",
    "\n",
    "rows_to_exclude = mini_in_product_name | limited_edition_in_product_name\n",
    "\n",
    "\n",
    "cleaned_df = combined_df[~rows_to_exclude]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170851\n",
      "13033\n"
     ]
    }
   ],
   "source": [
    "xxfiltered_df = combined_df.groupby('author_id').filter(lambda x: x['product_id'].nunique() > 6)\n",
    "print(len(xxfiltered_df))\n",
    "print(len(set(xxfiltered_df['author_id'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126027\n",
      "9259\n"
     ]
    }
   ],
   "source": [
    "filtered_df = cleaned_df.groupby('author_id').filter(lambda x: x['product_id'].nunique() > 6)\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "print(len(filtered_df))\n",
    "print(len(set(filtered_df['author_id'])))\n",
    "#set(filtered_df['author_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>product_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11777122</td>\n",
       "      <td>P232915 P466123 P421277 P500777 P475124 P48232...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>634369095</td>\n",
       "      <td>P466123 P456218 P453928 P472810 P465741 P45891...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>912025723</td>\n",
       "      <td>P399623 P500777 P480461 P504045 P475124 P47281...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>958443488</td>\n",
       "      <td>P466123 P456213 P481697 P480461 P482008 P48174...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>967124371</td>\n",
       "      <td>P7880 P430337 P4016 P466123 P421277 P405096 P4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9254</th>\n",
       "      <td>998853649</td>\n",
       "      <td>P456211 P470041 P447212 P447782 P447781 P45408...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9255</th>\n",
       "      <td>9990263118</td>\n",
       "      <td>P456566 P467655 P440307 P410400 P432668 P43454...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9256</th>\n",
       "      <td>9994328735</td>\n",
       "      <td>P281835 P421275 P428250 P454018 P469482 P41429...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9257</th>\n",
       "      <td>9996449006</td>\n",
       "      <td>P188307 P4010 P420699 P297524 P54509 P434546 P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9258</th>\n",
       "      <td>orderGen1698648</td>\n",
       "      <td>P455926 P502656 P446423 P455366 P500245 P46143...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9259 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            author_id                                         product_id\n",
       "0            11777122  P232915 P466123 P421277 P500777 P475124 P48232...\n",
       "1           634369095  P466123 P456218 P453928 P472810 P465741 P45891...\n",
       "2           912025723  P399623 P500777 P480461 P504045 P475124 P47281...\n",
       "3           958443488  P466123 P456213 P481697 P480461 P482008 P48174...\n",
       "4           967124371  P7880 P430337 P4016 P466123 P421277 P405096 P4...\n",
       "...               ...                                                ...\n",
       "9254        998853649  P456211 P470041 P447212 P447782 P447781 P45408...\n",
       "9255       9990263118  P456566 P467655 P440307 P410400 P432668 P43454...\n",
       "9256       9994328735  P281835 P421275 P428250 P454018 P469482 P41429...\n",
       "9257       9996449006  P188307 P4010 P420699 P297524 P54509 P434546 P...\n",
       "9258  orderGen1698648  P455926 P502656 P446423 P455366 P500245 P46143...\n",
       "\n",
       "[9259 rows x 2 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_columns = filtered_df[['author_id', 'product_id']]\n",
    "combined_reviews = selected_columns.groupby('author_id')['product_id'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "combined_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     support            itemsets\n",
      "36  0.057458  (P270594, P476414)\n",
      "37  0.051085  (P270594, P479841)\n",
      "38  0.079274  (P270594, P500633)\n",
      "39  0.064370  (P270594, P503936)\n",
      "40  0.056918  (P500633, P423688)\n",
      "41  0.054434  (P479841, P476414)\n",
      "42  0.058970  (P500633, P476414)\n",
      "43  0.055082  (P500633, P479841)\n",
      "44  0.067286  (P503936, P500633)\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Convert the 'reviews' into a list of transactions\n",
    "# Assuming `combined_reviews` is the DataFrame with aggregated reviews per author\n",
    "transactions = combined_reviews['product_id'].str.split().tolist()\n",
    "\n",
    "# Step 2: Create a DataFrame for one-hot encoding\n",
    "# Flatten all unique items (reviews) and create a unique item list\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "te = TransactionEncoder()\n",
    "te_array = te.fit(transactions).transform(transactions)\n",
    "df_encoded = pd.DataFrame(te_array, columns=te.columns_)\n",
    "\n",
    "# Step 3: Apply the Apriori algorithm\n",
    "frequent_itemsets = apriori(df_encoded, min_support=0.05, use_colnames=True)\n",
    "\n",
    "# Step 4: Focus on pairs of reviews\n",
    "frequent_pairs = frequent_itemsets[frequent_itemsets['itemsets'].apply(len) == 2]\n",
    "\n",
    "# Step 5: Generate association rules (optional, for insights)\n",
    "rules = association_rules(frequent_itemsets, metric=\"support\", min_threshold=0.05, num_itemsets=len(frequent_itemsets))\n",
    "\n",
    "# Display the frequent pairs\n",
    "print(frequent_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "antecedents consequents  support  confidence     lift\n",
      "    P503936     P500633 0.067286    0.575254 3.668234\n",
      "    P479841     P500633 0.055082    0.564159 3.597487\n",
      "    P479841     P476414 0.054434    0.557522 4.629684\n",
      "    P503936     P270594 0.064370    0.550323 3.671068\n",
      "    P270594     P500633 0.079274    0.528818 3.372128\n",
      "    P479841     P270594 0.051085    0.523230 3.490337\n",
      "    P500633     P270594 0.079274    0.505510 3.372128\n",
      "    P476414     P500633 0.058970    0.489686 3.122592\n",
      "    P476414     P270594 0.057458    0.477130 3.182815\n",
      "    P476414     P479841 0.054434    0.452018 4.629684\n",
      "    P270594     P503936 0.064370    0.429395 3.671068\n",
      "    P500633     P503936 0.067286    0.429063 3.668234\n",
      "    P270594     P476414 0.057458    0.383285 3.182815\n",
      "    P500633     P476414 0.058970    0.376033 3.122592\n",
      "    P500633     P423688 0.056918    0.362948 2.126919\n",
      "    P500633     P479841 0.055082    0.351240 3.597487\n",
      "    P270594     P479841 0.051085    0.340778 3.490337\n",
      "    P423688     P500633 0.056918    0.333544 2.126919\n"
     ]
    }
   ],
   "source": [
    "# Select and rename key columns for readability\n",
    "rules_display = rules[[\"antecedents\", \"consequents\", \"support\", \"confidence\", \"lift\"]].copy()\n",
    "\n",
    "# Convert frozensets to readable strings\n",
    "rules_display[\"antecedents\"] = rules_display[\"antecedents\"].apply(lambda x: ', '.join(list(x)))\n",
    "rules_display[\"consequents\"] = rules_display[\"consequents\"].apply(lambda x: ', '.join(list(x)))\n",
    "\n",
    "# Sort by confidence or any other metric (optional)\n",
    "rules_display = rules_display.sort_values(by=\"confidence\", ascending=False)\n",
    "\n",
    "# Print the rules as a nice table\n",
    "print(rules_display.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try to quantify this\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
