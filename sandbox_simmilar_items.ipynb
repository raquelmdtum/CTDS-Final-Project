{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Load the CSV data into a DataFrame\n",
    "df = pd.read_csv(\"data/skincare.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster based on secondary category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "secondary_category = set(df['secondary_category'])\n",
    "\n",
    "category_items_dict = {}\n",
    "for category in secondary_category:\n",
    "   items = list(df[df['secondary_category'] == category]['product_id'])\n",
    "   category_items_dict[category] = items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get similar items based on the highlights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(set_a, set_b):\n",
    "   \"\"\"\n",
    "   Calculate the Jaccard Similarity between two sets.\n",
    "   \"\"\"\n",
    "   intersection = len(set_a.intersection(set_b))\n",
    "   union = len(set_a.union(set_b))\n",
    "   return intersection / union if union != 0 else 0.0\n",
    "\n",
    "def similarity_search(df, token_list):\n",
    "   \"\"\"\n",
    "   Perform similarity search based on Jaccard similarity between IDs and a token list.\n",
    "   \n",
    "   :param df: A pandas DataFrame with columns ['id', 'tokens'].\n",
    "   :param token_list: A list of tokens to compare against.\n",
    "   :return: A DataFrame with IDs and their Jaccard similarity scores, sorted by similarity score.\n",
    "   \"\"\"\n",
    "   # Convert the token list to a set\n",
    "   token_set = set(token_list)\n",
    "   \n",
    "   # List to store the similarity scores\n",
    "   similarity_scores = []\n",
    "   \n",
    "   # Iterate over the rows of the DataFrame\n",
    "   for index, row in df.iterrows():\n",
    "      product_id = row['product_id']\n",
    "      title = row['product_name']\n",
    "      # Convert the tokens for this ID to a set (assumed to be a string)\n",
    "      id_token_set = set(row['highlights'].split(\", \"))\n",
    "      \n",
    "      # Calculate Jaccard similarity\n",
    "      similarity_score = jaccard_similarity(id_token_set, token_set)\n",
    "      \n",
    "      # Append the result as a tuple (id, score)\n",
    "      similarity_scores.append((product_id, title, similarity_score, (row['highlights'])))\n",
    "   \n",
    "   # Convert the list of similarity scores to a DataFrame\n",
    "   similarity_df = pd.DataFrame(similarity_scores, columns=['product_id', 'product_name', 'similarity_score', 'highlights'])\n",
    "   \n",
    "   # Sort the DataFrame by the 'similarity_score' column in descending order\n",
    "   similarity_df_sorted = similarity_df.sort_values(by='similarity_score', ascending=False).reset_index(drop=True)\n",
    "   \n",
    "   return similarity_df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1927\n",
      "my highlights: ['Vegan', 'Collagen', 'Hypoallergenic', 'Loss of firmness', 'Dry', 'Combo', 'Normal']\n",
      "     product_id                                 product_name  \\\n",
      "0       P388262         GENIUS Ultimate Anti-Aging Eye Cream   \n",
      "1       P392945  GENIUS Ultimate Anti-Aging Vitamin C+ Serum   \n",
      "2       P384537             GENIUS Ultimate Anti-Aging Cream   \n",
      "3       P421277                 GENIUS Liquid Collagen Serum   \n",
      "4       P439055         GENIUS Sleeping Collagen Moisturizer   \n",
      "...         ...                                          ...   \n",
      "1922    P479633               Pore Remedy Purifying Mud Mask   \n",
      "1923    P474371               Evercalm Gentle Cleansing Milk   \n",
      "1924    P504056  Perfect Canvas Smooth, Prep & Plump Essence   \n",
      "1925    P470049           Clearcalm Clarifying Clay Cleanser   \n",
      "1926    P455612     Vitamin C & Bearberry Instant Glow Serum   \n",
      "\n",
      "      similarity_score                                         highlights  \n",
      "0                1.000  Vegan, Collagen, Hypoallergenic, Loss of firmn...  \n",
      "1                1.000  Vegan, Collagen, Hypoallergenic, Loss of firmn...  \n",
      "2                1.000  Vegan, Collagen, Hypoallergenic, Loss of firmn...  \n",
      "3                0.875  Vegan, Loss of firmness, Collagen, Hypoallerge...  \n",
      "4                0.875  Vegan, Loss of firmness, Collagen, Hypoallerge...  \n",
      "...                ...                                                ...  \n",
      "1922             0.000                    Pores, Dullness, Uneven Texture  \n",
      "1923             0.000  Clean + Planet Positive, Pores, Redness, Acne,...  \n",
      "1924             0.000  Dullness, Uneven Texture, Hyaluronic Acid, Plu...  \n",
      "1925             0.000  Acne, Blemishes, Fragrance Free, Gluten Free, ...  \n",
      "1926             0.000  allure 2020 Best of Beauty Award Winner, Dulln...  \n",
      "\n",
      "[1927 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# for now we are taking the eye cream\n",
    "items = category_items_dict['Eye Care']\n",
    "\n",
    "# item I am looking for (now we only took the first one later we shall do the real one)\n",
    "my_item = items[0]\n",
    "\n",
    "# here I have remove the item I am searching for, this is where I take the product of certian secondary kind\n",
    "#filtered_df = df[df['product_id'].isin(items[1:])][['product_id','product_name', 'highlights']]\n",
    "filtered_df = df[['product_id','product_name', 'highlights']]\n",
    "print(len(filtered_df))\n",
    "\n",
    "\n",
    "# The token list to compare against\n",
    "token_list = list(df[df['product_id'] == my_item]['highlights'])[0].split(\", \")\n",
    "\n",
    "# Perform similarity search and get sorted results\n",
    "similarity_results_sorted = similarity_search(filtered_df, token_list)\n",
    "\n",
    "print(\"my highlights:\", token_list)\n",
    "\n",
    "# Output sorted similarity scores\n",
    "my_sim_items = similarity_results_sorted[['similarity_score', 'highlights']]\n",
    "\n",
    "print(similarity_results_sorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Products similar to the chosen one (ID: P388262):\n",
      "0       P439055\n",
      "1       P421277\n",
      "2       P432045\n",
      "3       P311143\n",
      "4       P384537\n",
      "6       P392945\n",
      "9       P453818\n",
      "11      P388262\n",
      "13      P447504\n",
      "15      P456990\n",
      "16      P504443\n",
      "31      P503197\n",
      "354     P453822\n",
      "569     P503809\n",
      "844     P455610\n",
      "1024    P481825\n",
      "1586    P480192\n",
      "Name: product_id, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from datasketch import MinHash, MinHashLSH\n",
    "\n",
    "highlights = df[['product_id', 'highlights']]\n",
    "\n",
    "chosen_highlight_row = list(df[df['product_id'] == my_item]['highlights'])[0].split(\", \")\n",
    "\n",
    "def crate_mihashes(highlights, threshold=0.5, num_perm=128):\n",
    "   minhashes = {}\n",
    "   lsh = MinHashLSH(threshold=0.5, num_perm=128)\n",
    "   for _, row in highlights.iterrows():\n",
    "      product_id = row['product_id']\n",
    "      tokens = row['highlights'].split(\", \")\n",
    "      m = MinHash(num_perm=128)\n",
    "      for token in tokens:\n",
    "         m.update(token.encode('utf8'))\n",
    "      minhashes[product_id] = m\n",
    "      lsh.insert(product_id, m)\n",
    "   return minhashes, lsh\n",
    "\n",
    "\n",
    "minhashes, lsh = crate_mihashes(highlights)\n",
    "\n",
    "# Query for similar items\n",
    "chosen_minhash = minhashes[my_item]\n",
    "similar_product_ids = lsh.query(chosen_minhash)\n",
    "similar_products = df[df['product_id'].isin(similar_product_ids)]['product_id']\n",
    "print(f\"Products similar to the chosen one (ID: {my_item}):\\n{similar_products}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "P388262\n"
     ]
    }
   ],
   "source": [
    "items_in_both = set(list(similar_products)).intersection(set(list(similarity_results_sorted[['product_id']])))\n",
    "\n",
    "\n",
    "print(items_in_both)\n",
    "print(my_item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
