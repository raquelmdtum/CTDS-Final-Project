{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(set_a, set_b):\n",
    "   \"\"\"\n",
    "   Calculate the Jaccard Similarity between two sets.\n",
    "   \"\"\"\n",
    "   intersection = len(set_a.intersection(set_b))\n",
    "   union = len(set_a.union(set_b))\n",
    "   return intersection / union if union != 0 else 0.0\n",
    "\n",
    "def similarity_search_highlights(df, token_list):\n",
    "   \"\"\"\n",
    "   Perform similarity search based on Jaccard similarity between df and a token list.\n",
    "   \n",
    "   :param df: A pandas DataFrame with columns ['product_id','product_name', 'highlights'].\n",
    "   :param token_list: A list of tokens to compare against (highlights).\n",
    "   :return: A DataFrame with IDs and their Jaccard similarity scores, sorted by similarity score.\n",
    "   \"\"\"\n",
    "   # Convert the token list to a set\n",
    "   token_set = set(token_list)\n",
    "   \n",
    "   # List to store the similarity scores\n",
    "   similarity_scores = []\n",
    "   \n",
    "   # Iterate over the rows of the DataFrame\n",
    "   for index, row in df.iterrows():\n",
    "      product_id = row['product_id']\n",
    "      title = row['product_name']\n",
    "      # Convert the tokens for this ID to a set (assumed to be a string)\n",
    "      id_token_set = set(row['highlights'].split(\", \"))\n",
    "      \n",
    "      # Calculate Jaccard similarity\n",
    "      similarity_score = jaccard_similarity(id_token_set, token_set)\n",
    "      \n",
    "      # Append the result as a tuple (id, score)\n",
    "      similarity_scores.append((product_id, title, similarity_score, (row['highlights'])))\n",
    "   \n",
    "   # Convert the list of similarity scores to a DataFrame\n",
    "   similarity_df = pd.DataFrame(similarity_scores, columns=['product_id', 'product_name', 'similarity_score_highlights', 'highlights'])\n",
    "   \n",
    "   # Sort the DataFrame by the 'similarity_score' column in descending order\n",
    "   similarity_df_sorted = similarity_df.sort_values(by='similarity_score_highlights', ascending=False).reset_index(drop=True)\n",
    "   \n",
    "   similarity_df_sorted['rank_highlights'] = range(1, len(similarity_df_sorted) + 1)\n",
    "   \n",
    "   return similarity_df_sorted\n",
    "\n",
    "def custom_tokenizer(text):\n",
    "   return text.split(\", \")\n",
    "\n",
    "def similarity_search_ingredients(df, query):\n",
    "   \"\"\"\n",
    "   Perform a similarity search based on cosine similarity of TF-IDF vectors.\n",
    "\n",
    "   Parameters:\n",
    "   - query (str): The input query string.\n",
    "   - df (pd.DataFrame): A DataFrame containing 'id' and 'ingredients' columns.\n",
    "\n",
    "   Returns:\n",
    "   - results_df (pd.DataFrame): Rows from the original DataFrame sorted by similarity.\n",
    "   \"\"\"\n",
    "   # Initialize TfidfVectorizer with a custom tokenizer (adjust lowercase as needed)\n",
    "   vectorizer = TfidfVectorizer(tokenizer=custom_tokenizer, lowercase=False)\n",
    "\n",
    "   # Extract the 'ingredients' column\n",
    "   ingredients = df['ingredients']\n",
    "\n",
    "   # Fit and transform the ingredients\n",
    "   tfidf_matrix = vectorizer.fit_transform(ingredients)\n",
    "\n",
    "   # Transform the query into the TF-IDF space\n",
    "   query_tfidf = vectorizer.transform([query])\n",
    "\n",
    "   # Compute cosine similarity between the query and all documents\n",
    "   similarities = cosine_similarity(query_tfidf, tfidf_matrix).flatten()\n",
    "\n",
    "   # Add similarity scores to the DataFrame\n",
    "   df['similarity_score_ingredients'] = similarities\n",
    "\n",
    "   # Sort the DataFrame by similarity scores in descending order\n",
    "   results_df = df.sort_values(by='similarity_score_ingredients', ascending=False).reset_index(drop=True)\n",
    "   \n",
    "   results_df['rank_ingredients'] = range(1, len(results_df) + 1)\n",
    "\n",
    "   return results_df\n",
    "\n",
    "def reciprocal_rank_fusion(df_highlights, df_ingredients, k=60):\n",
    "   \"\"\"\n",
    "   Compute Reciprocal Rank Fusion (RRF) scores based on rank_highlights and rank_ingredients.\n",
    "\n",
    "   Parameters:\n",
    "   - df_highlights (pd.DataFrame): DataFrame containing 'product_id', 'rank_highlights', and other relevant columns.\n",
    "   - df_ingredients (pd.DataFrame): DataFrame containing 'product_id', 'rank_ingredients', and other relevant columns.\n",
    "   - k (int): A constant for RRF computation (default=60).\n",
    "\n",
    "   Returns:\n",
    "   - combined_df (pd.DataFrame): A new DataFrame with overall RRF scores and combined ranking.\n",
    "   \"\"\"\n",
    "   # Merge the two DataFrames on 'product_id'\n",
    "   merged_df = pd.merge(\n",
    "      df_highlights,  # Include all columns from df_highlights\n",
    "      df_ingredients[['product_id', 'rank_ingredients']],  # Include only product_id and rank_ingredients\n",
    "      on='product_id',\n",
    "      how='inner'\n",
    "   )\n",
    "\n",
    "   # Fill missing ranks with a large value (e.g., very low relevance)\n",
    "   merged_df['rank_highlights'] = merged_df['rank_highlights'].fillna(float('inf'))\n",
    "   merged_df['rank_ingredients'] = merged_df['rank_ingredients'].fillna(float('inf'))\n",
    "\n",
    "   # Compute the RRF score\n",
    "   merged_df['rrf_score'] = (\n",
    "      1 / (k + merged_df['rank_highlights']) +\n",
    "      1 / (k + merged_df['rank_ingredients'])\n",
    "   )\n",
    "\n",
    "   # Sort by the RRF score in descending order\n",
    "   merged_df = merged_df.sort_values(by='rrf_score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "   # Add a new rank based on the RRF score\n",
    "   merged_df['overall_rank'] = range(1, len(merged_df) + 1)\n",
    "   \n",
    "   return merged_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run code for specific product_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_items(product_id, n = 5):\n",
    "   \"\"\"\n",
    "   Retrieve the top N products most similar to a given product based on highlights and ingredients.\n",
    "\n",
    "   This function takes a product ID, performs similarity searches on the product's highlights and ingredients, \n",
    "   and combines the results using a reciprocal rank fusion algorithm. It returns the top N most similar products.\n",
    "\n",
    "   Parameters:\n",
    "   ----------\n",
    "   product_id : int or str\n",
    "      The ID of the product for which similar items are being searched.\n",
    "   n : int, optional\n",
    "      The number of similar products to return. Default is 5.\n",
    "\n",
    "   Returns:\n",
    "    - merged_results (pd.DataFrame): A new DataFrame containing top n similar items\n",
    "   \"\"\"\n",
    "   # load the data\n",
    "   df = pd.read_csv(\"processed_data/skincare.csv\")\n",
    "\n",
    "   # get the selected product\n",
    "   product = df[df['product_id'] == product_id]\n",
    "\n",
    "   # get the product highlights and ingredients\n",
    "   product_highlights =  list(product['highlights'])[0].split(\", \")\n",
    "   product_ingredients = str(product['ingredients'])\n",
    "\n",
    "   # remove the product I am searching for\n",
    "   df = df[(df['product_id'] != product_id)]#[['product_id','product_name', 'highlights']]\n",
    "\n",
    "   # perform similarity searches\n",
    "   highlights_similarity_results = similarity_search_highlights(df, product_highlights)\n",
    "   ingredients_similarity_results = similarity_search_ingredients(df, product_ingredients)\n",
    "\n",
    "   # combine similarity searches with reciprocal rank fusion algorithm\n",
    "   merged_results = reciprocal_rank_fusion(highlights_similarity_results, ingredients_similarity_results)\n",
    "   \n",
    "   # Return only the top-n products\n",
    "   return merged_results[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  product_id                                   product_name  \\\n",
      "0    P448200             Benefiance Wrinkle Smoothing Cream   \n",
      "1    P422000              Creamy Eye Treatment with Avocado   \n",
      "2    P474036                                  Aloe Vera Gel   \n",
      "3    P421996  Ultra Facial Moisturizing Cream with Squalane   \n",
      "4    P448203         Benefiance Wrinkle Smoothing Eye Cream   \n",
      "\n",
      "   similarity_score_highlights  \\\n",
      "0                     0.333333   \n",
      "1                     0.250000   \n",
      "2                     0.363636   \n",
      "3                     0.230769   \n",
      "4                     0.230769   \n",
      "\n",
      "                                          highlights  rank_highlights  \\\n",
      "0  Anti-Aging, Dryness, Loss of firmness, Dry, Co...               72   \n",
      "1  Clean at Sephora, Fragrance Free, Dryness, Wit...              195   \n",
      "2  Dry, Combo, Normal, Dryness, Redness, Vegan, F...               36   \n",
      "3  Refill Available, Clean at Sephora, Fragrance ...              259   \n",
      "4  Anti-Aging, Dryness, Dry, Combo, Normal, Oily,...              252   \n",
      "\n",
      "   rank_ingredients  rrf_score  overall_rank  \n",
      "0                15   0.020909             1  \n",
      "1                 1   0.020315             2  \n",
      "2                43   0.020125             3  \n",
      "3                 2   0.019264             4  \n",
      "4                 3   0.019078             5  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\miniconda\\envs\\ds\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "merged = get_similar_items(\"P432045\")\n",
    "print(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    GENIUS Liquid Collagen Lip Treatment\n",
      "Name: product_name, dtype: object\n",
      "0    GENIUS Ultimate Anti-Aging Vitamin C+ Serum\n",
      "1               GENIUS Ultimate Anti-Aging Cream\n",
      "2           GENIUS Ultimate Anti-Aging Eye Cream\n",
      "3                   GENIUS Liquid Collagen Serum\n",
      "4           GENIUS Sleeping Collagen Moisturizer\n",
      "Name: product_name, dtype: object\n",
      "0                Creamy Eye Treatment with Avocado\n",
      "1    Ultra Facial Moisturizing Cream with Squalane\n",
      "2           Benefiance Wrinkle Smoothing Eye Cream\n",
      "3             SHIKULIME Mega Hydrating Moisturizer\n",
      "4                     YUZU-C Eye Awakening Essence\n",
      "Name: product_name, dtype: object\n",
      "0               Benefiance Wrinkle Smoothing Cream\n",
      "1                Creamy Eye Treatment with Avocado\n",
      "2                                    Aloe Vera Gel\n",
      "3    Ultra Facial Moisturizing Cream with Squalane\n",
      "4           Benefiance Wrinkle Smoothing Eye Cream\n",
      "Name: product_name, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\miniconda\\envs\\ds\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "product_id_input = \"P432045\" #input(\"Enter the product_id: \")\n",
    "\n",
    "# load the data\n",
    "df = pd.read_csv(\"processed_data/skincare.csv\")\n",
    "\n",
    "# get the selected product\n",
    "product = df[df['product_id'] == product_id_input]\n",
    "\n",
    "# get the product highlights and ingredients\n",
    "product_highlights =  list(product['highlights'])[0].split(\", \")\n",
    "product_ingredients = str(product['ingredients'])\n",
    "\n",
    "# remove the product I am searching for\n",
    "df = df[(df['product_id'] != product_id_input)]#[['product_id','product_name', 'highlights']]\n",
    "\n",
    "# perform similarity searches\n",
    "highlights_similarity_results = similarity_search_highlights(df, product_highlights)\n",
    "ingredients_similarity_results = similarity_search_ingredients(df, product_ingredients)\n",
    "\n",
    "# combine similarity searches with reciprocal rank fusion algorithm\n",
    "merged_results = reciprocal_rank_fusion(highlights_similarity_results, ingredients_similarity_results)\n",
    "\n",
    "print(product['product_name'])\n",
    "print(highlights_similarity_results['product_name'].head(5))\n",
    "print(ingredients_similarity_results['product_name'].head(5))\n",
    "print(merged_results['product_name'].head(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
