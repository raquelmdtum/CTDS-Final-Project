{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(set_a, set_b):\n",
    "   \"\"\"\n",
    "   Calculate the Jaccard Similarity between two sets.\n",
    "   \"\"\"\n",
    "   intersection = len(set_a.intersection(set_b))\n",
    "   union = len(set_a.union(set_b))\n",
    "   return intersection / union if union != 0 else 0.0\n",
    "\n",
    "def similarity_search_highlights(df, token_list):\n",
    "   \"\"\"\n",
    "   Perform similarity search based on Jaccard similarity between df and a token list.\n",
    "   \n",
    "   :param df: A pandas DataFrame with columns ['product_id','product_name', 'highlights'].\n",
    "   :param token_list: A list of tokens to compare against (highlights).\n",
    "   :return: A DataFrame with IDs and their Jaccard similarity scores, sorted by similarity score.\n",
    "   \"\"\"\n",
    "   # Convert the token list to a set\n",
    "   token_set = set(token_list)\n",
    "   \n",
    "   # List to store the similarity scores\n",
    "   similarity_scores = []\n",
    "   \n",
    "   # Iterate over the rows of the DataFrame\n",
    "   for index, row in df.iterrows():\n",
    "      product_id = row['product_id']\n",
    "      title = row['product_name']\n",
    "      # Convert the tokens for this ID to a set (assumed to be a string)\n",
    "      id_token_set = set(row['highlights'].split(\", \"))\n",
    "      \n",
    "      # Calculate Jaccard similarity\n",
    "      similarity_score = jaccard_similarity(id_token_set, token_set)\n",
    "      \n",
    "      # Append the result as a tuple (id, score)\n",
    "      similarity_scores.append((product_id, title, similarity_score, (row['highlights'])))\n",
    "   \n",
    "   # Convert the list of similarity scores to a DataFrame\n",
    "   similarity_df = pd.DataFrame(similarity_scores, columns=['product_id', 'product_name', 'similarity_score_highlights', 'highlights'])\n",
    "   \n",
    "   # Sort the DataFrame by the 'similarity_score' column in descending order\n",
    "   similarity_df_sorted = similarity_df.sort_values(by='similarity_score_highlights', ascending=False).reset_index(drop=True)\n",
    "   \n",
    "   similarity_df_sorted['rank_highlights'] = range(1, len(similarity_df_sorted) + 1)\n",
    "   \n",
    "   return similarity_df_sorted\n",
    "\n",
    "def custom_tokenizer(text):\n",
    "   return text.split(\", \")\n",
    "\n",
    "def similarity_search_ingredients(df, query):\n",
    "   \"\"\"\n",
    "   Perform a similarity search based on cosine similarity of TF-IDF vectors.\n",
    "\n",
    "   Parameters:\n",
    "   - query (str): The input query string.\n",
    "   - df (pd.DataFrame): A DataFrame containing 'id' and 'ingredients' columns.\n",
    "\n",
    "   Returns:\n",
    "   - results_df (pd.DataFrame): Rows from the original DataFrame sorted by similarity.\n",
    "   \"\"\"\n",
    "   # Initialize TfidfVectorizer with a custom tokenizer (adjust lowercase as needed)\n",
    "   vectorizer = TfidfVectorizer(tokenizer=custom_tokenizer, lowercase=False)\n",
    "\n",
    "   # Extract the 'ingredients' column\n",
    "   ingredients = df['ingredients']\n",
    "\n",
    "   # Fit and transform the ingredients\n",
    "   tfidf_matrix = vectorizer.fit_transform(ingredients)\n",
    "\n",
    "   # Transform the query into the TF-IDF space\n",
    "   query_tfidf = vectorizer.transform([query])\n",
    "\n",
    "   # Compute cosine similarity between the query and all documents\n",
    "   similarities = cosine_similarity(query_tfidf, tfidf_matrix).flatten()\n",
    "\n",
    "   # Add similarity scores to the DataFrame\n",
    "   df['similarity_score_ingredients'] = similarities\n",
    "\n",
    "   # Sort the DataFrame by similarity scores in descending order\n",
    "   results_df = df.sort_values(by='similarity_score_ingredients', ascending=False).reset_index(drop=True)\n",
    "   \n",
    "   results_df['rank_ingredients'] = range(1, len(results_df) + 1)\n",
    "\n",
    "   return results_df\n",
    "\n",
    "def reciprocal_rank_fusion(df_highlights, df_ingredients, k=60):\n",
    "   \"\"\"\n",
    "   Compute Reciprocal Rank Fusion (RRF) scores based on rank_highlights and rank_ingredients.\n",
    "\n",
    "   Parameters:\n",
    "   - df_highlights (pd.DataFrame): DataFrame containing 'product_id', 'rank_highlights', and other relevant columns.\n",
    "   - df_ingredients (pd.DataFrame): DataFrame containing 'product_id', 'rank_ingredients', and other relevant columns.\n",
    "   - k (int): A constant for RRF computation (default=60).\n",
    "\n",
    "   Returns:\n",
    "   - combined_df (pd.DataFrame): A new DataFrame with overall RRF scores and combined ranking.\n",
    "   \"\"\"\n",
    "   # Merge the two DataFrames on 'product_id'\n",
    "   merged_df = pd.merge(\n",
    "      df_highlights,  # Include all columns from df_highlights\n",
    "      df_ingredients[['product_id', 'rank_ingredients']],  # Include only product_id and rank_ingredients\n",
    "      on='product_id',\n",
    "      how='inner'\n",
    "   )\n",
    "\n",
    "   # Fill missing ranks with a large value (e.g., very low relevance)\n",
    "   merged_df['rank_highlights'] = merged_df['rank_highlights'].fillna(float('inf'))\n",
    "   merged_df['rank_ingredients'] = merged_df['rank_ingredients'].fillna(float('inf'))\n",
    "\n",
    "   # Compute the RRF score\n",
    "   merged_df['rrf_score'] = (\n",
    "      1 / (k + merged_df['rank_highlights']) +\n",
    "      1 / (k + merged_df['rank_ingredients'])\n",
    "   )\n",
    "\n",
    "   # Sort by the RRF score in descending order\n",
    "   merged_df = merged_df.sort_values(by='rrf_score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "   # Add a new rank based on the RRF score\n",
    "   merged_df['overall_rank'] = range(1, len(merged_df) + 1)\n",
    "   \n",
    "   return merged_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run code for specific product_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    GENIUS Liquid Collagen Lip Treatment\n",
      "Name: product_name, dtype: object\n",
      "0    GENIUS Ultimate Anti-Aging Vitamin C+ Serum\n",
      "1               GENIUS Ultimate Anti-Aging Cream\n",
      "2           GENIUS Ultimate Anti-Aging Eye Cream\n",
      "3                   GENIUS Liquid Collagen Serum\n",
      "4           GENIUS Sleeping Collagen Moisturizer\n",
      "Name: product_name, dtype: object\n",
      "0                Creamy Eye Treatment with Avocado\n",
      "1    Ultra Facial Moisturizing Cream with Squalane\n",
      "2           Benefiance Wrinkle Smoothing Eye Cream\n",
      "3             SHIKULIME Mega Hydrating Moisturizer\n",
      "4                     YUZU-C Eye Awakening Essence\n",
      "Name: product_name, dtype: object\n",
      "0               Benefiance Wrinkle Smoothing Cream\n",
      "1                Creamy Eye Treatment with Avocado\n",
      "2                                    Aloe Vera Gel\n",
      "3    Ultra Facial Moisturizing Cream with Squalane\n",
      "4           Benefiance Wrinkle Smoothing Eye Cream\n",
      "Name: product_name, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\miniconda\\envs\\ds\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "product_id_input = \"P432045\" #input(\"Enter the product_id: \")\n",
    "\n",
    "# load the data\n",
    "df = pd.read_csv(\"processed_data/skincare.csv\")\n",
    "\n",
    "# get the selected product\n",
    "product = df[df['product_id'] == product_id_input]\n",
    "\n",
    "# get the product highlights and ingredients\n",
    "product_highlights =  list(product['highlights'])[0].split(\", \")\n",
    "product_ingredients = str(product['ingredients'])\n",
    "\n",
    "# remove the product I am searching for\n",
    "df = df[(df['product_id'] != product_id_input)]#[['product_id','product_name', 'highlights']]\n",
    "\n",
    "# perform similarity searches\n",
    "highlights_similarity_results = similarity_search_highlights(df, product_highlights)\n",
    "ingredients_similarity_results = similarity_search_ingredients(df, product_ingredients)\n",
    "\n",
    "# combine similarity searches with reciprocal rank fusion algorithm\n",
    "merged_results = reciprocal_rank_fusion(highlights_similarity_results, ingredients_similarity_results)\n",
    "\n",
    "print(product['product_name'])\n",
    "print(highlights_similarity_results['product_name'].head(5))\n",
    "print(ingredients_similarity_results['product_name'].head(5))\n",
    "print(merged_results['product_name'].head(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
